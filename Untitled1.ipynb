{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First construct a table. for each observation, get the predicted probability and the prediction 0 vs 1. I keep the observation ID as well, in my case patient id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting point here is after you've trained your model and validated using the test set.\n",
    "#you need y_test and predicted probability for each row\n",
    "\n",
    "##generating table\n",
    "\n",
    "# store predicted probability for \"1\"\n",
    "percent_noshow = pd.DataFrame({'percent_noshow': y_pred_model_xgb_PT[:,1]}) \n",
    "\n",
    "#then combine into table with observation ID, y_test, and predicted probability\n",
    "test_table = pd.concat([X_test['PatientId'].reset_index(drop=True), y_test.reset_index(drop=True), percent_noshow.reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, construct a range for values you want to bin into, similar to how you're binning in your figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to divide my range of predicted probabilities into 100, but you could jubmit into any number of bins\n",
    "\n",
    "#this fucntion gives the min and max values in a list, or column in my case\n",
    "def minmax(val_list):\n",
    "    min_val = min(val_list)\n",
    "    max_val = max(val_list)\n",
    "\n",
    "    return (min_val, max_val)\n",
    "\n",
    "gap = minmax(test_table.percent_noshow) #this applies the function to find highest and lowest values\n",
    "\n",
    "## This code divides the range into pieces, and finds what the step size should be to get that number of pieces\n",
    "step_size = (gap[1]-gap[0])/100 ##change 100 here to whatever bin size you need\n",
    "\n",
    "##this generates a list of numbers, starting from the lowest number and ending with your highest number, using the stepsize above\n",
    "cutoffs = np.arange(gap[0], gap[1], step_size)\n",
    "cutoffs ## print what that your list looks like. you should see your range divided into equal step sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "no_show_precision = [] # generate empty list\n",
    "for i in cutoffs:\n",
    "    predicted_proba = test_table['percent_noshow']\n",
    "    no_show_likely = test_table[test_table['percent_noshow']>i] #find all entries in your table more likely than your cutoff\n",
    "    no_show_unlikely = test_table[test_table['percent_noshow']<i] # find all entries less likely than cutoff\n",
    "    precision = no_show_likely[no_show_likely.noshow ==1].shape[0] /no_show_likely.shape[0] ## find preciion given the cutoff for each cutoff, what is the precision\n",
    "    percentage = (i-gap[0])/(gap[1]-gap[0])*100 #percentile of range\n",
    "    proportion = no_show_likely.shape[0] / test_table.shape[0] # proportion no shows\n",
    "    total = no_show_likely.shape[0] ##total number of positive predictions\n",
    "    data = [predicted_proba,percentage, precision, proportion, total] #storing the data generated in the loop\n",
    "    no_show_precision.append(data) #appending data to bottom row in the empty set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_show_precision = pd.DataFrame(no_show_precision, columns = ['predicted_proba','percentile', 'precision', 'proportion', 'total']) ##colecting all results\n",
    "no_show_precision[no_show_precision['percentile']>70] ##sanity check here that cutoff thresholds are working. I use percentile of range, but you can use predict probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# retrieve performance metrics\n",
    "x_axis = no_show_precision['percentile'] # you can use predicted proba here\n",
    "# plot log loss\n",
    "fig, ax = pyplot.subplots(figsize=(15,15))\n",
    "ax.plot(x_axis, no_show_precision['precision'], label='Precision') ##add plot for precision\n",
    "ax.plot(x_axis, no_show_precision['proportion'], label='Proportion') ##add plot of proportion of data captured\n",
    "ax.legend(prop={'size': 15})\n",
    "plt.axvline(75, color='black', linestyle='--') ## threshold for calling sometheing positive case\n",
    "pyplot.ylabel('Precision / Proportion (out of 1)', size=20)\n",
    "pyplot.title('Tradeoffs for Predicted Probablity Threshold', size=30)\n",
    "pyplot.xlabel('Predicted Probability', size=20)\n",
    "pyplot.show()\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
